{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We're back again with 29,752 Jeopardy! questions and answers. Based on the text, we will compare two Unsupervised Learning topic generation models: Latent Dirichlet Allocation (LDA) and Non-Negative Matrix Factorization (NMF). These methods will cluster our questions into ten different topics. Then, we will use these generated features to create a Supervised regression model to predict if a question belongs to a certain topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy = pd.read_csv('JEOPARDY_CSV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#jeopardy.rename(columns={' Category':'category',\n",
    "      # ' Question':'question', ' Answer':'answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = jeopardy[' Category'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29752 entries, 0 to 216929\n",
      "Data columns (total 10 columns):\n",
      "Show Number        29752 non-null int64\n",
      " Air Date          29752 non-null object\n",
      " Round             29752 non-null object\n",
      " Category          29752 non-null object\n",
      " Value             29752 non-null object\n",
      " Question          29752 non-null object\n",
      " Answer            29752 non-null object\n",
      "question_answer    29752 non-null object\n",
      "clean_qa           29752 non-null object\n",
      "topics             29752 non-null int64\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = ['Category','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = list(df[df['count'] >= 100].Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEFORE & AFTER',\n",
       " 'SCIENCE',\n",
       " 'LITERATURE',\n",
       " 'AMERICAN HISTORY',\n",
       " 'POTPOURRI',\n",
       " 'WORLD HISTORY',\n",
       " 'WORD ORIGINS',\n",
       " 'COLLEGES & UNIVERSITIES',\n",
       " 'HISTORY',\n",
       " 'SPORTS',\n",
       " 'U.S. CITIES',\n",
       " 'WORLD GEOGRAPHY',\n",
       " 'BODIES OF WATER',\n",
       " 'ANIMALS',\n",
       " 'STATE CAPITALS',\n",
       " 'BUSINESS & INDUSTRY',\n",
       " 'ISLANDS',\n",
       " 'WORLD CAPITALS',\n",
       " 'U.S. GEOGRAPHY',\n",
       " 'RELIGION',\n",
       " 'SHAKESPEARE',\n",
       " 'OPERA',\n",
       " 'LANGUAGES',\n",
       " 'BALLET',\n",
       " 'TELEVISION',\n",
       " 'FICTIONAL CHARACTERS',\n",
       " 'TRANSPORTATION',\n",
       " 'PEOPLE',\n",
       " 'RHYME TIME',\n",
       " 'ART & ARTISTS',\n",
       " 'STUPID ANSWERS',\n",
       " 'THE BIBLE',\n",
       " 'ART',\n",
       " 'BOOKS & AUTHORS',\n",
       " 'U.S. HISTORY',\n",
       " 'FOOD',\n",
       " 'MUSEUMS',\n",
       " 'AMERICANA',\n",
       " 'SCIENCE & NATURE',\n",
       " 'COMMON BONDS',\n",
       " 'HOLIDAYS & OBSERVANCES',\n",
       " 'GEOGRAPHY',\n",
       " '3-LETTER WORDS',\n",
       " 'ANNUAL EVENTS',\n",
       " 'AMERICAN LITERATURE',\n",
       " 'CLASSICAL MUSIC',\n",
       " 'POP MUSIC',\n",
       " 'AUTHORS',\n",
       " 'POETS & POETRY',\n",
       " 'QUOTATIONS',\n",
       " 'HODGEPODGE',\n",
       " 'MYTHOLOGY',\n",
       " 'NONFICTION',\n",
       " 'THE MOVIES',\n",
       " 'WORLD CITIES',\n",
       " 'MUSICAL INSTRUMENTS',\n",
       " 'AROUND THE WORLD',\n",
       " 'THE CIVIL WAR',\n",
       " 'MUSIC',\n",
       " 'U.S. PRESIDENTS',\n",
       " 'COMPOSERS',\n",
       " 'ASTRONOMY',\n",
       " 'FOOD & DRINK',\n",
       " '4-LETTER WORDS',\n",
       " 'BIOLOGY',\n",
       " 'HISTORIC NAMES',\n",
       " 'MOUNTAINS',\n",
       " 'POTENT POTABLES',\n",
       " 'EUROPEAN HISTORY',\n",
       " 'HOMOPHONES',\n",
       " 'MEDICINE',\n",
       " 'EXPLORERS',\n",
       " 'ORGANIZATIONS',\n",
       " 'SCIENTISTS',\n",
       " 'ARCHITECTURE',\n",
       " 'WEIGHTS & MEASURES',\n",
       " 'FIRST LADIES',\n",
       " 'TRAVEL & TOURISM',\n",
       " 'FRUITS & VEGETABLES',\n",
       " 'THE BODY HUMAN',\n",
       " 'MAGAZINES',\n",
       " 'IN THE DICTIONARY',\n",
       " 'FAMOUS AMERICANS',\n",
       " 'ZOOLOGY',\n",
       " 'AWARDS',\n",
       " 'NATURE',\n",
       " 'FOREIGN WORDS & PHRASES',\n",
       " 'VOCABULARY',\n",
       " 'FASHION',\n",
       " 'THEATRE',\n",
       " '19th CENTURY AMERICA',\n",
       " 'CHEMISTRY',\n",
       " '5-LETTER WORDS',\n",
       " 'WORLD LEADERS',\n",
       " 'PHYSICS',\n",
       " 'GOVERNMENT & POLITICS',\n",
       " 'U.S. STATES',\n",
       " 'ABBREV.',\n",
       " 'NOTABLE NAMES',\n",
       " 'GENERAL SCIENCE',\n",
       " 'ARTISTS',\n",
       " 'THE AMERICAN REVOLUTION',\n",
       " '10-LETTER WORDS',\n",
       " 'ANATOMY',\n",
       " 'FAMOUS NAMES',\n",
       " 'ACTORS & ACTRESSES',\n",
       " 'LAKES & RIVERS',\n",
       " 'COUNTRIES OF THE WORLD',\n",
       " 'BIRDS',\n",
       " 'ODDS & ENDS',\n",
       " 'POP CULTURE',\n",
       " 'PEOPLE IN HISTORY',\n",
       " 'HAIL TO THE CHIEF',\n",
       " 'FAMILIAR PHRASES',\n",
       " 'POETRY',\n",
       " 'HEALTH & MEDICINE',\n",
       " 'MAMMALS',\n",
       " 'SIGNS & SYMBOLS',\n",
       " 'U.S.A.',\n",
       " 'POLITICIANS',\n",
       " 'QUOTES',\n",
       " 'BOTANY',\n",
       " 'INVENTORS',\n",
       " 'CLASSICAL COMPOSERS',\n",
       " 'LETTER PERFECT',\n",
       " 'SCULPTURE',\n",
       " 'HISTORIC AMERICANS',\n",
       " 'THE OLD TESTAMENT',\n",
       " 'SINGERS',\n",
       " 'ROYALTY',\n",
       " 'DOUBLE TALK',\n",
       " 'MUSICAL THEATRE',\n",
       " 'COLORS',\n",
       " 'ARCHAEOLOGY',\n",
       " 'BODY LANGUAGE',\n",
       " 'WORLD LITERATURE',\n",
       " 'EUROPE',\n",
       " 'THE ELEMENTS',\n",
       " 'TECHNOLOGY',\n",
       " 'MIDDLE NAMES',\n",
       " 'THE OSCARS',\n",
       " 'ANCIENT HISTORY',\n",
       " 'PLAYWRIGHTS',\n",
       " 'FAMOUS WOMEN',\n",
       " 'LIBRARIES',\n",
       " 'GEOLOGY',\n",
       " 'THE 50 STATES',\n",
       " 'LEFTOVERS',\n",
       " 'BESTSELLERS',\n",
       " 'THE HUMAN BODY']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = jeopardy[jeopardy[' Category'].isin(categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spenser\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['question_answer'] = df[' Question'] + df[' Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spenser\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['clean_qa'] = df['question_answer'].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spenser\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "w2v = word2vec.Word2Vec(\n",
    "    df['clean_qa'],\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=10,  # Minimum word count threshold.\n",
    "    window=6,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['F', 'o', 'r', ' ', 't', 'h', 'e', 'l', 'a', 's', '8', 'y', 'f', 'i', ',', 'G', 'w', 'u', 'n', 'd', 'p', 'g', 'm', \"'\", 'C', 'c', 'I', 'A', 'b', 'B', '3', '1', '2', '.', 'k', 'R', '&', 'S', 'W', '0', 'j', 'O', '(', 'L', ')', 'v', '!', 'K', 'M', 'x', 'z', ';', '9', 'T', '5', '\"', 'N', 'P', '4', '-', 'D', 'J', '6', '7', ':', 'q', 'E', 'H', 'V', 'U', '%', '<', '=', '/', '_', '>', 'Y', 'Z', '$', 'Q', '\\\\', '?', '“', '”', '’', 'X', 'é', 'í', 'á', 'ó', '#'])\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab = w2v.wv.vocab.keys()\n",
    "print(vocab)\n",
    "#print(w2v.wv.most_similar(positive=['army', 'man'], negative=['woman']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Xw2v = w2v.fit(df['clean_qa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english', max_df = 100, min_df = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = tfidf.fit(df['clean_qa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tfidf.transform(df['clean_qa']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<29752x4206 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 107986 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29752, 4206)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(10, max_iter=10,\n",
    "learning_method='online',\n",
    "learning_offset=50.,\n",
    "learning_decay = 0.7,\n",
    "random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda = lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_lda = lda.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_topics(model, vectorizer, top_n=10):\n",
    "   for idx, topic in enumerate(model.components_):\n",
    "       print(\"Topic %d:\" % (idx))\n",
    "       print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                       for i in topic.argsort()[:-top_n - 1:-1]])\n",
    "       print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Model:\n",
      "Topic 0:\n",
      "[('derived', 48.765983969795826), ('late', 43.748010347653953), ('using', 40.690556329113754), ('40', 39.615694081092002), ('gas', 36.839162477405011), ('wild', 36.264318116004894), ('jersey', 36.127885122826811), ('free', 34.78341105323252), ('divided', 34.620428959619915), ('metal', 34.413687974552097)]\n",
      "====================================================================================================\n",
      "Topic 1:\n",
      "[('spoken', 56.795920474411581), ('dutch', 51.802380804478403), ('gulf', 46.475726256528212), ('street', 43.400453628951595), ('formed', 42.117864013156257), ('dog', 41.864878320078965), ('ship', 40.005207903012135), ('mark', 39.674446158105553), ('coast', 39.247481130956594), ('moon', 37.459316776122407)]\n",
      "====================================================================================================\n",
      "Topic 2:\n",
      "[('takes', 46.621455684590238), ('member', 42.628964466279356), ('cities', 41.780903544413142), ('foot', 40.936432620922091), ('elected', 38.982990689831851), ('2009', 37.631029019798056), ('jefferson', 36.76631356468463), ('painting', 36.760347706155599), ('sir', 36.350601145399764), ('japanese', 36.146023581777271)]\n",
      "====================================================================================================\n",
      "Topic 3:\n",
      "[('peak', 48.559084540664394), ('types', 46.312764360718958), ('contains', 44.353922374784759), ('india', 42.929462853437272), ('food', 42.219749306896468), ('port', 40.467064719771969), ('plant', 40.301640716953791), ('100', 39.164764590731693), ('right', 38.744907850167422), ('statue', 38.695403929691125)]\n",
      "====================================================================================================\n",
      "Topic 4:\n",
      "[('order', 47.311121113684983), ('mother', 45.850914849711437), ('female', 45.302898206839174), ('mount', 45.07834621097367), ('according', 39.999835580281321), ('didn', 39.583126201865092), ('30', 39.054883978040202), ('roosevelt', 37.786463179664807), ('invented', 36.264621860925459), ('square', 35.281783080646356)]\n",
      "====================================================================================================\n",
      "Topic 5:\n",
      "[('given', 41.850127907654006), ('johnson', 40.835023066260682), ('birds', 39.997145816500421), ('sound', 39.181800464096902), ('modern', 39.024928475943298), ('game', 38.67906032462755), ('emperor', 37.961389776342649), ('devoted', 36.855464649127022), ('peter', 36.672334153400236), ('shakespeare', 36.048488684912392)]\n",
      "====================================================================================================\n",
      "Topic 6:\n",
      "[('africa', 50.510445737254514), ('army', 42.797661708261963), ('pacific', 41.506019653675288), ('animals', 38.845621467526364), ('festival', 38.541738189133383), ('actress', 37.479899640257443), ('military', 36.397916696641893), ('thisthe', 34.988320825776078), ('prime', 34.582963775400593), ('jesus', 34.374317749168156)]\n",
      "====================================================================================================\n",
      "Topic 7:\n",
      "[('variety', 45.891068673689446), ('ocean', 44.998901483030707), ('fish', 41.943576472540435), ('golden', 41.318255372733788), ('books', 40.991259533320381), ('nickname', 40.464242046303717), ('grand', 40.449631025906811), ('run', 39.115324379830554), ('stone', 37.712768740231077), ('dr', 36.668702839843199)]\n",
      "====================================================================================================\n",
      "Topic 8:\n",
      "[('history', 45.73401142555128), ('building', 45.329823302807455), ('original', 43.547367629856275), ('spain', 39.039559499308531), ('tell', 37.74265600702121), ('continent', 37.23095857382355), ('hero', 36.713073392543279), ('brown', 36.48949667906988), ('power', 35.12822281869137), ('plays', 34.066469523868633)]\n",
      "====================================================================================================\n",
      "Topic 9:\n",
      "[('mean', 50.501714096980777), ('phrase', 46.441025305169681), ('royal', 44.557530391633875), ('horse', 43.764494881627861), ('northern', 40.722835649887891), ('mountains', 40.230672899423062), ('florida', 38.286697417132011), ('dance', 37.577283214575729), ('tree', 36.972814669331768), ('adams', 35.65452393161037)]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA Model:\")\n",
    "print_topics(lda, tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the topics generated by LDA mostly lack coherent meaning. \n",
    "    Topic 0: Misc.\n",
    "    Topic 1: Misc. - Compare use of Dutch to NMF Topic 4\n",
    "    Topic 2: Misc. - Politics, contains Jefferson and Japanese\n",
    "    Topic 3: Some Geographical content\n",
    "    Topic 4: Misc. - Contains mother and female, but also mount and Roosevelt\n",
    "    Topic 5: Misc. - Maybe Shakespeare related\n",
    "    Topic 6: Misc.\n",
    "    Topic 7: Misc.\n",
    "    Topic 8: Some Historical content\n",
    "    Topic 9: Misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=10, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, beta=1, eta=0.1, init=None, l1_ratio=0.5, max_iter=200,\n",
       "  n_components=10, nls_max_iter=2000, random_state=1, shuffle=False,\n",
       "  solver='cd', sparseness=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('horse', 3.2482111937393352), ('race', 0.22403469654060248), ('racing', 0.16814883533728442), ('nile', 0.14291646486177598), ('crown', 0.13662653261471722), ('winged', 0.11750627784939911), ('triple', 0.11704734444098196), ('drawn', 0.088758738396920972), ('lee', 0.086461189776939396), ('wild', 0.084097009739033779)]\n",
      "====================================================================================================\n",
      "Topic 1:\n",
      "[('spoken', 3.3403620019198379), ('languages', 0.92757637191391762), ('widely', 0.29467359115899316), ('dialect', 0.10853632261427593), ('united', 0.097903432557003608), ('morning', 0.080150318934918002), ('continentafrica', 0.064494877377648155), ('guinea', 0.049588259753491751), ('portuguese', 0.043083190231663453), ('continent', 0.040499163236133687)]\n",
      "====================================================================================================\n",
      "Topic 2:\n",
      "[('peak', 2.582106579368824), ('mount', 2.2593353947847419), ('mountains', 0.98001854128311061), ('range', 0.67812349189283871), ('foot', 0.53927526981259366), ('everest', 0.28831995094196572), ('colorado', 0.26061232876312351), ('border', 0.17959748699966641), ('14', 0.16164233690501589), ('mt', 0.13763971264958125)]\n",
      "====================================================================================================\n",
      "Topic 3:\n",
      "[('mean', 3.4026288681259733), ('adjective', 0.23201931575208518), ('verb', 0.21335282503047318), ('face', 0.13620562271552764), ('fifth', 0.093773205124551645), ('worn', 0.072255741037261748), ('card', 0.060347324393678167), ('baseball', 0.059549811106706749), ('tissue', 0.054697533963548733), ('doesn', 0.052092832422346656)]\n",
      "====================================================================================================\n",
      "Topic 4:\n",
      "[('dutch', 3.3419556739962748), ('orange', 0.20556091930541984), ('cake', 0.19492057788780637), ('cape', 0.10496924638570156), ('royal', 0.079050704791982063), ('colony', 0.072719713649597298), ('gogh', 0.071580083856695662), ('netherlands', 0.070024872492022341), ('treaty', 0.068448287090149371), ('kind', 0.063675483602507299)]\n",
      "====================================================================================================\n",
      "Topic 5:\n",
      "[('ocean', 2.6404071793767012), ('pacific', 2.2271103657457862), ('atlantic', 0.48772279702842214), ('port', 0.40483693787367603), ('half', 0.17863933549873839), ('arm', 0.12842660703896602), ('territory', 0.096488329476895257), ('coastline', 0.089793737654656022), ('size', 0.073758348517651826), ('arctic', 0.063880267285881837)]\n",
      "====================================================================================================\n",
      "Topic 6:\n",
      "[('types', 3.3109535103060859), ('basic', 0.16194543738032111), ('different', 0.094418982739042909), ('sweet', 0.073187714705687218), ('cells', 0.063097417795312735), ('organisms', 0.060092996358508559), ('particle', 0.056248491083389363), ('spot', 0.053538107186909406), ('liquor', 0.045780944154156809), ('matter', 0.042648900861595569)]\n",
      "====================================================================================================\n",
      "Topic 7:\n",
      "[('africa', 3.3286000867574002), ('cape', 0.29318309857746699), ('populous', 0.19463343438108527), ('countries', 0.10809239911951668), ('desert', 0.10135933614312169), ('mandela', 0.089285546743635924), ('horn', 0.052769080364747652), ('kenya', 0.051655864405832953), ('asia', 0.050826847105200378), ('continent', 0.048736866091171595)]\n",
      "====================================================================================================\n",
      "Topic 8:\n",
      "[('derived', 3.3085688897332308), ('colorwhite', 0.074926536242787167), ('probably', 0.073958583679734721), ('andes', 0.066608103097461277), ('worn', 0.0383636813712721), ('metal', 0.037474926377671414), ('bones', 0.037435791118517352), ('synonym', 0.037398661652159208), ('daniel', 0.037382680745170989), ('partly', 0.036644865722071387)]\n",
      "====================================================================================================\n",
      "Topic 9:\n",
      "[('gulf', 3.217966285331209), ('persian', 0.52547498266552506), ('arabian', 0.23590134326190229), ('suez', 0.15043186618482507), ('finland', 0.13690049527953826), ('connects', 0.11838739539972372), ('alabama', 0.11244782219682406), ('arm', 0.095446183468845813), ('coastline', 0.093453413186103534), ('channel', 0.093335233042847326)]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print_topics(nmf, tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    On the other hand, the NMF topics are much more closely clustered.\n",
    "    Topic 0: Horse Racing\n",
    "    Topic 1: Languages\n",
    "    Topic 2: Mountains\n",
    "    Topic 3: Misc. - Parts of speech and baseball\n",
    "    Topic 4: Dutch Culture\n",
    "    Topic 5: Oceanography\n",
    "    Topic 6: Misc. - Some Science content\n",
    "    Topic 7: African Culture / Geography\n",
    "    Topic 8: Misc.\n",
    "    Topic 9: Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf_X = nmf.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29752, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misc = []\n",
    "topics = []\n",
    "for i in range(nmf_X.shape[0]):\n",
    "    \n",
    "    topics.append(nmf_X[i].argsort()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spenser\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df['topics'] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_X[4].argsort()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "Y = df['topics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    27370\n",
       "2      650\n",
       "5      404\n",
       "7      249\n",
       "0      235\n",
       "3      226\n",
       "4      212\n",
       "1      174\n",
       "6      145\n",
       "8       87\n",
       "Name: topics, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topics'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-81c728788183>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-53-81c728788183>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    df2 = df[df['topics'] = '9']\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df2 = df[df['topics'] = '9']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show Number        True\n",
       " Air Date          True\n",
       " Round             True\n",
       " Category          True\n",
       " Value             True\n",
       " Question          True\n",
       " Answer            True\n",
       "question_answer    True\n",
       "clean_qa           True\n",
       "topics             True\n",
       "Name: topics, dtype: bool"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['topics'] == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients: \n",
      " [[ 0.24578712 -0.10914346 -0.07565727 ..., -0.02225573 -0.0241235\n",
      "  -0.03464927]\n",
      " [-0.05160611 -0.07120198 -0.05352192 ..., -0.01502025 -0.01349794\n",
      "  -0.02217961]\n",
      " [-0.16187153 -0.22391032 -0.15898888 ..., -0.04613455 -0.04996332\n",
      "  -0.07198022]\n",
      " ..., \n",
      " [-0.0715992  -0.12556724 -0.06884514 ..., -0.02022884 -0.01986579\n",
      "  -0.0320533 ]\n",
      " [-0.0287491  -0.04100943 -0.02843624 ..., -0.00812084 -0.00766585\n",
      "  -0.0126783 ]\n",
      " [-0.19460234  0.09209627  0.3096135  ...,  0.12955731  0.19647281\n",
      "  -0.23332211]]\n",
      "\n",
      "Intercept: \n",
      " [-5.26157525 -5.72637163 -4.51297475 -5.37844581 -5.46162696 -4.95333437\n",
      " -5.82559735 -5.34517442 -6.29654017  3.25681077]\n",
      "\n",
      "R-squared:\n",
      "0.954850997087\n",
      "0.914610118458\n"
     ]
    }
   ],
   "source": [
    "log_regr = linear_model.LogisticRegression()\n",
    "log_regr.fit(X_train, Y_train)\n",
    "\n",
    "print('\\nCoefficients: \\n', log_regr.coef_)\n",
    "print('\\nIntercept: \\n', log_regr.intercept_)\n",
    "print('\\nR-squared:')\n",
    "print(log_regr.score(X_test, Y_test))\n",
    "print(1 - (1-log_regr.score(X_test, Y_test))*(len(Y_test)-1)/(len(Y_test)-X_test.shape[1]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
