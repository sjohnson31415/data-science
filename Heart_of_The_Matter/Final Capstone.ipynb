{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "import collections\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import glob\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION AND EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_a = pd.read_csv('set_a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_b = pd.read_csv('set_b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_a_timing = pd.read_csv('set_a_timing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD8CAYAAABdCyJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npCIGiSSpyP8Hwm5lkF5RAxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d4ffddae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TRAIN_DIR = \"../Final Capstone/set_a\"\n",
    "list_of_wavs = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
    "#for item in list_of_wavs: \n",
    "rate, image = wav.read('artifact__201012172012.wav')\n",
    "%matplotlib inline\n",
    "plt.plot(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>cycle</th>\n",
       "      <th>sound</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set_a/normal__201102081321.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>10021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>set_a/normal__201102081321.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>20759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>set_a/normal__201102081321.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>S1</td>\n",
       "      <td>35075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>set_a/normal__201102081321.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>S2</td>\n",
       "      <td>47244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>set_a/normal__201102081321.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>S1</td>\n",
       "      <td>62992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fname  cycle sound  location\n",
       "0  set_a/normal__201102081321.wav      1    S1     10021\n",
       "1  set_a/normal__201102081321.wav      1    S2     20759\n",
       "2  set_a/normal__201102081321.wav      2    S1     35075\n",
       "3  set_a/normal__201102081321.wav      2    S2     47244\n",
       "4  set_a/normal__201102081321.wav      3    S1     62992"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a_timing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LOGISTIC REGRESSION AND SUPPORT VECTOR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = X_train.reshape(74,220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test2 = X_test.reshape(50,220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(X_train2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_lg = lg.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  1,  1,  3],\n",
       "       [ 0,  4,  2,  2],\n",
       "       [ 0,  2,  8,  3],\n",
       "       [ 0,  2,  2,  6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64000000000000001"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg.score(X_test2,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_train2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test2,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'artifact': 100%|████| 40/40 [00:19<00:00,  2.06it/s]\n",
      "Saving vectors of label - 'extrahls': 100%|████| 19/19 [00:07<00:00,  2.44it/s]\n",
      "Saving vectors of label - 'murmur': 100%|██████| 34/34 [00:14<00:00,  2.38it/s]\n",
      "Saving vectors of label - 'normal': 100%|██████| 31/31 [00:13<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, Conv1D, MaxPooling2D, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 4\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.8337 - acc: 0.26 - 1s 13ms/step - loss: 11.5415 - acc: 0.2838\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.1454 - acc: 0.29 - 0s 325us/step - loss: 11.2768 - acc: 0.2838\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3789 - acc: 0.34 - 0s 365us/step - loss: 10.2832 - acc: 0.3514\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1658 - acc: 0.35 - 0s 318us/step - loss: 10.5519 - acc: 0.3243\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0812 - acc: 0.31 - 0s 527us/step - loss: 11.3262 - acc: 0.2973\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.8367 - acc: 0.26 - 0s 507us/step - loss: 11.5440 - acc: 0.2838\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.8367 - acc: 0.26 - 0s 487us/step - loss: 11.5440 - acc: 0.2838\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.5849 - acc: 0.28 - 0s 406us/step - loss: 11.5440 - acc: 0.2838\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.8367 - acc: 0.26 - 0s 527us/step - loss: 11.5440 - acc: 0.2838\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.8367 - acc: 0.26 - 0s 338us/step - loss: 11.7619 - acc: 0.2703\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9778 - acc: 0.31 - 0s 385us/step - loss: 11.4547 - acc: 0.2838\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.9632 - acc: 0.375 - 0s 392us/step - loss: 9.9237 - acc: 0.3784\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7600 - acc: 0.453 - 0s 473us/step - loss: 8.8831 - acc: 0.4459\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.9868 - acc: 0.375 - 0s 379us/step - loss: 10.5976 - acc: 0.3378\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1636 - acc: 0.35 - 0s 500us/step - loss: 10.0970 - acc: 0.3649\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0738 - acc: 0.37 - 0s 419us/step - loss: 10.2372 - acc: 0.3649\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7680 - acc: 0.359 - 0s 399us/step - loss: 10.1905 - acc: 0.3378\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3183 - acc: 0.421 - 0s 412us/step - loss: 10.0194 - acc: 0.3784\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5422 - acc: 0.34 - 0s 480us/step - loss: 9.9888 - acc: 0.3784\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3257 - acc: 0.35 - 0s 521us/step - loss: 9.8015 - acc: 0.3919\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1600 - acc: 0.421 - 0s 412us/step - loss: 9.2291 - acc: 0.4189\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0664 - acc: 0.437 - 0s 521us/step - loss: 9.3659 - acc: 0.4189\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5969 - acc: 0.390 - 0s 467us/step - loss: 9.3890 - acc: 0.4054\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.8293 - acc: 0.32 - 0s 473us/step - loss: 10.0194 - acc: 0.3784\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3561 - acc: 0.34 - 0s 487us/step - loss: 9.8279 - acc: 0.3784\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1048 - acc: 0.406 - 0s 433us/step - loss: 9.2700 - acc: 0.3919\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3183 - acc: 0.421 - 0s 460us/step - loss: 9.3659 - acc: 0.4189\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3183 - acc: 0.421 - 0s 487us/step - loss: 9.8119 - acc: 0.3784\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8146 - acc: 0.453 - 0s 480us/step - loss: 9.3959 - acc: 0.4054\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8102 - acc: 0.390 - 0s 392us/step - loss: 10.0092 - acc: 0.3784\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3183 - acc: 0.421 - 0s 399us/step - loss: 9.7613 - acc: 0.3919\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.2829 - acc: 0.484 - 0s 372us/step - loss: 8.2526 - acc: 0.4865\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0664 - acc: 0.437 - 0s 473us/step - loss: 8.9841 - acc: 0.4324\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4364 - acc: 0.406 - 0s 331us/step - loss: 9.9037 - acc: 0.3784\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.6972 - acc: 0.515 - 0s 318us/step - loss: 7.7461 - acc: 0.5135\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3183 - acc: 0.421 - 0s 304us/step - loss: 9.1481 - acc: 0.4324\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0721 - acc: 0.437 - 0s 372us/step - loss: 9.1530 - acc: 0.4324\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8146 - acc: 0.453 - 0s 385us/step - loss: 9.0400 - acc: 0.4324\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3257 - acc: 0.35 - 0s 358us/step - loss: 9.5837 - acc: 0.4054\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0664 - acc: 0.437 - 0s 541us/step - loss: 9.1481 - acc: 0.4324\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7624 - acc: 0.453 - 0s 521us/step - loss: 8.6674 - acc: 0.4595\n",
      "Epoch 42/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.5554 - acc: 0.531 - 0s 494us/step - loss: 7.4056 - acc: 0.5405\n",
      "Epoch 43/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5629 - acc: 0.468 - 0s 426us/step - loss: 8.2770 - acc: 0.4865\n",
      "Epoch 44/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.3109 - acc: 0.484 - 0s 297us/step - loss: 8.7125 - acc: 0.4595\n",
      "Epoch 45/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8648 - acc: 0.437 - 0s 460us/step - loss: 8.3203 - acc: 0.4730\n",
      "Epoch 46/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.3109 - acc: 0.484 - 0s 392us/step - loss: 8.9303 - acc: 0.4459\n",
      "Epoch 47/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0102 - acc: 0.437 - 0s 480us/step - loss: 8.8816 - acc: 0.4459\n",
      "Epoch 48/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0481 - acc: 0.35 - 0s 331us/step - loss: 10.2150 - acc: 0.3514\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9357 - acc: 0.31 - 0s 325us/step - loss: 10.3292 - acc: 0.3514\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.2926 - acc: 0.29 - 0s 338us/step - loss: 10.8556 - acc: 0.3243\n",
      "Epoch 51/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0960 - acc: 0.421 - 0s 311us/step - loss: 9.1737 - acc: 0.4189\n",
      "Epoch 52/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0630 - acc: 0.437 - 0s 379us/step - loss: 9.1452 - acc: 0.4324\n",
      "Epoch 53/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5507 - acc: 0.468 - 0s 338us/step - loss: 8.9199 - acc: 0.4459\n",
      "Epoch 54/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0738 - acc: 0.37 - 0s 473us/step - loss: 9.5837 - acc: 0.4054\n",
      "Epoch 55/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8146 - acc: 0.453 - 0s 331us/step - loss: 9.3659 - acc: 0.4189\n",
      "Epoch 56/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.3109 - acc: 0.484 - 0s 325us/step - loss: 8.7125 - acc: 0.4595\n",
      "Epoch 57/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8220 - acc: 0.390 - 0s 304us/step - loss: 9.9208 - acc: 0.3784\n",
      "Epoch 58/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1270 - acc: 0.421 - 0s 325us/step - loss: 8.9827 - acc: 0.4324\n",
      "Epoch 59/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5627 - acc: 0.468 - 0s 291us/step - loss: 8.4947 - acc: 0.4730\n",
      "Epoch 60/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8059 - acc: 0.390 - 0s 372us/step - loss: 9.1342 - acc: 0.4324\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 9.3265 - acc: 0.421 - 0s 358us/step - loss: 9.3730 - acc: 0.4189\n",
      "Epoch 62/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5701 - acc: 0.406 - 0s 318us/step - loss: 9.3659 - acc: 0.4189\n",
      "Epoch 63/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.3109 - acc: 0.484 - 0s 399us/step - loss: 8.4947 - acc: 0.4730\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5627 - acc: 0.468 - 0s 548us/step - loss: 9.1481 - acc: 0.4324\n",
      "Epoch 65/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0664 - acc: 0.437 - 0s 453us/step - loss: 8.9303 - acc: 0.4459\n",
      "Epoch 66/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0664 - acc: 0.437 - 0s 575us/step - loss: 9.1481 - acc: 0.4324\n",
      "Epoch 67/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1338 - acc: 0.35 - 0s 311us/step - loss: 9.8534 - acc: 0.3784\n",
      "Epoch 68/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.2988 - acc: 0.468 - 0s 399us/step - loss: 8.2664 - acc: 0.4730\n",
      "Epoch 69/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.5557 - acc: 0.531 - 0s 385us/step - loss: 8.0593 - acc: 0.5000\n",
      "Epoch 70/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.9917 - acc: 0.500 - 0s 331us/step - loss: 8.2186 - acc: 0.4865\n",
      "Epoch 71/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.9498 - acc: 0.421 - 0s 318us/step - loss: 8.6116 - acc: 0.4459\n",
      "Epoch 72/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5701 - acc: 0.406 - 0s 318us/step - loss: 8.9303 - acc: 0.4459\n",
      "Epoch 73/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.8072 - acc: 0.515 - 0s 352us/step - loss: 7.8474 - acc: 0.5135\n",
      "Epoch 74/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8274 - acc: 0.437 - 0s 338us/step - loss: 9.1592 - acc: 0.4189\n",
      "Epoch 75/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.9964 - acc: 0.437 - 0s 433us/step - loss: 8.6520 - acc: 0.4595\n",
      "Epoch 76/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.1756 - acc: 0.421 - 0s 548us/step - loss: 9.0287 - acc: 0.4324\n",
      "Epoch 77/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5701 - acc: 0.406 - 0s 358us/step - loss: 8.9303 - acc: 0.4459\n",
      "Epoch 78/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0668 - acc: 0.437 - 0s 379us/step - loss: 8.9306 - acc: 0.4459\n",
      "Epoch 79/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5701 - acc: 0.406 - 0s 406us/step - loss: 9.1481 - acc: 0.4324\n",
      "Epoch 80/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5701 - acc: 0.406 - 0s 439us/step - loss: 9.3659 - acc: 0.4189\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8146 - acc: 0.453 - 0s 460us/step - loss: 9.3659 - acc: 0.4189\n",
      "Epoch 82/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0738 - acc: 0.37 - 0s 365us/step - loss: 10.0194 - acc: 0.3784\n",
      "Epoch 83/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8748 - acc: 0.375 - 0s 453us/step - loss: 9.4116 - acc: 0.4054\n",
      "Epoch 84/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.2908 - acc: 0.468 - 0s 338us/step - loss: 8.6951 - acc: 0.4459\n",
      "Epoch 85/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.5858 - acc: 0.515 - 0s 338us/step - loss: 8.3031 - acc: 0.4730\n",
      "Epoch 86/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8162 - acc: 0.453 - 0s 379us/step - loss: 9.1495 - acc: 0.4324\n",
      "Epoch 87/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.5701 - acc: 0.406 - 0s 311us/step - loss: 9.5540 - acc: 0.4054\n",
      "Epoch 88/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.2710 - acc: 0.29 - 0s 365us/step - loss: 10.6191 - acc: 0.3378\n",
      "Epoch 89/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8146 - acc: 0.453 - 0s 399us/step - loss: 8.9303 - acc: 0.4459\n",
      "Epoch 90/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0664 - acc: 0.437 - 0s 480us/step - loss: 9.5837 - acc: 0.4054\n",
      "Epoch 91/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8526 - acc: 0.375 - 0s 352us/step - loss: 9.8280 - acc: 0.3784\n",
      "Epoch 92/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5627 - acc: 0.468 - 0s 358us/step - loss: 8.4947 - acc: 0.4730\n",
      "Epoch 93/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.3109 - acc: 0.484 - 0s 325us/step - loss: 8.7125 - acc: 0.4595\n",
      "Epoch 94/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0439 - acc: 0.437 - 0s 399us/step - loss: 8.8391 - acc: 0.4459\n",
      "Epoch 95/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5627 - acc: 0.468 - 0s 358us/step - loss: 8.2769 - acc: 0.4865\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.6173 - acc: 0.453 - 0s 345us/step - loss: 8.3241 - acc: 0.4730\n",
      "Epoch 97/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.3109 - acc: 0.484 - 0s 318us/step - loss: 8.7125 - acc: 0.4595\n",
      "Epoch 98/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5627 - acc: 0.468 - 0s 331us/step - loss: 8.7125 - acc: 0.4595\n",
      "Epoch 99/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.8072 - acc: 0.515 - 0s 365us/step - loss: 8.2769 - acc: 0.4865\n",
      "Epoch 100/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8220 - acc: 0.390 - 0s 392us/step - loss: 9.1482 - acc: 0.4324\n",
      "50/50 [==============================] - ETA:  - 0s 2ms/step\n",
      "Test score: 9.34849533081\n",
      "Test accuracy: 0.42\n"
     ]
    }
   ],
   "source": [
    "#make dense only model\n",
    "# Build the Neural Network\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=220))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "X_train3 = X_train.reshape(74,220)\n",
    "X_test3 = X_test.reshape(50,220)\n",
    "# Train and test\n",
    "model.fit(X_train3, y_train_hot, epochs=100, batch_size=64)\n",
    "score, acc = model.evaluate(X_test3, y_test_hot, batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1D = X_train.reshape(74,220,1)\n",
    "X_test_1D = X_test.reshape(50,220,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.1967 - acc: 0.31 - 1s 13ms/step - loss: 10.5030 - acc: 0.2973\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.6165 - acc: 0.359 - 0s 1ms/step - loss: 10.2077 - acc: 0.3108\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.3431 - acc: 0.328 - 0s 1ms/step - loss: 8.5387 - acc: 0.3784\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7557 - acc: 0.359 - 0s 1ms/step - loss: 9.7443 - acc: 0.3649\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.2652 - acc: 0.453 - 0s 2ms/step - loss: 9.3176 - acc: 0.3919\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.0543 - acc: 0.32 - 0s 1ms/step - loss: 9.6142 - acc: 0.3514\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.1752 - acc: 0.468 - 0s 1ms/step - loss: 8.6399 - acc: 0.4324\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4922 - acc: 0.390 - 0s 1ms/step - loss: 9.4796 - acc: 0.3919\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.9967 - acc: 0.29 - 0s 1ms/step - loss: 10.8175 - acc: 0.3108\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.0989 - acc: 0.421 - 0s 1ms/step - loss: 9.7474 - acc: 0.3784\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.2927 - acc: 0.32 - 0s 2ms/step - loss: 10.4265 - acc: 0.3243\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.3302 - acc: 0.29 - 0s 1ms/step - loss: 11.3238 - acc: 0.2973\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5775 - acc: 0.34 - 0s 1ms/step - loss: 10.8906 - acc: 0.3243\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.3270 - acc: 0.34 - 0s 1ms/step - loss: 10.2384 - acc: 0.3514\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 10.5775 - acc: 0.34 - 0s 1ms/step - loss: 10.4652 - acc: 0.3378\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 11.0903 - acc: 0.25 - 0s 1ms/step - loss: 11.1163 - acc: 0.2568\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.7408 - acc: 0.484 - 0s 2ms/step - loss: 8.2194 - acc: 0.4595\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.6875 - acc: 0.421 - 0s 2ms/step - loss: 8.3847 - acc: 0.4459\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.0313 - acc: 0.437 - 0s 2ms/step - loss: 8.5832 - acc: 0.4054\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.4215 - acc: 0.484 - 0s 2ms/step - loss: 7.7255 - acc: 0.4730\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.2798 - acc: 0.484 - 0s 2ms/step - loss: 8.8116 - acc: 0.4459\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7407 - acc: 0.437 - 0s 2ms/step - loss: 8.7514 - acc: 0.4189\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8966 - acc: 0.343 - 0s 2ms/step - loss: 9.8085 - acc: 0.3514\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.4143 - acc: 0.453 - 0s 2ms/step - loss: 8.5841 - acc: 0.4459\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.4590 - acc: 0.343 - 0s 1ms/step - loss: 9.4876 - acc: 0.3514\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.9560 - acc: 0.406 - 0s 2ms/step - loss: 9.2929 - acc: 0.3784\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8371 - acc: 0.375 - 0s 2ms/step - loss: 9.5968 - acc: 0.3919\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.8801 - acc: 0.421 - 0s 2ms/step - loss: 9.2048 - acc: 0.4054\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.6269 - acc: 0.421 - 0s 1ms/step - loss: 8.3330 - acc: 0.4459\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.0904 - acc: 0.546 - 0s 2ms/step - loss: 7.7347 - acc: 0.5000\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.2218 - acc: 0.531 - 0s 2ms/step - loss: 7.9624 - acc: 0.4865\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.6605 - acc: 0.500 - 0s 2ms/step - loss: 7.5285 - acc: 0.5000\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.2717 - acc: 0.390 - 0s 2ms/step - loss: 8.8031 - acc: 0.4189\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.7091 - acc: 0.421 - 0s 1ms/step - loss: 8.4035 - acc: 0.4459\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.7598 - acc: 0.484 - 0s 1ms/step - loss: 7.6817 - acc: 0.4730\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.2628 - acc: 0.468 - 0s 1ms/step - loss: 8.6709 - acc: 0.4459\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.2356 - acc: 0.515 - 0s 1ms/step - loss: 7.3469 - acc: 0.5135\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.7630 - acc: 0.515 - 0s 1ms/step - loss: 8.2386 - acc: 0.4865\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.0080 - acc: 0.468 - 0s 1ms/step - loss: 8.2328 - acc: 0.4595\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.4523 - acc: 0.531 - 0s 1ms/step - loss: 7.3169 - acc: 0.5405\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.2807 - acc: 0.453 - 0s 2ms/step - loss: 8.0329 - acc: 0.4730\n",
      "Epoch 42/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.9664 - acc: 0.500 - 0s 1ms/step - loss: 8.4145 - acc: 0.4730\n",
      "Epoch 43/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.4614 - acc: 0.515 - 0s 1ms/step - loss: 7.5422 - acc: 0.5135\n",
      "Epoch 44/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.0378 - acc: 0.625 - 0s 1ms/step - loss: 6.3110 - acc: 0.6081\n",
      "Epoch 45/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.8769 - acc: 0.625 - 0s 2ms/step - loss: 6.3896 - acc: 0.5946\n",
      "Epoch 46/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.1824 - acc: 0.515 - 0s 1ms/step - loss: 7.2965 - acc: 0.5135\n",
      "Epoch 47/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.5959 - acc: 0.578 - 0s 1ms/step - loss: 6.5727 - acc: 0.5676\n",
      "Epoch 48/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.2714 - acc: 0.578 - 0s 1ms/step - loss: 6.6752 - acc: 0.5541\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.2240 - acc: 0.593 - 0s 1ms/step - loss: 6.2598 - acc: 0.5946\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.4546 - acc: 0.437 - 0s 1ms/step - loss: 9.0546 - acc: 0.4054\n",
      "Epoch 51/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.3563 - acc: 0.515 - 0s 1ms/step - loss: 6.8707 - acc: 0.5405\n",
      "Epoch 52/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.7054 - acc: 0.484 - 0s 1ms/step - loss: 7.5076 - acc: 0.5000\n",
      "Epoch 53/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 8.5503 - acc: 0.468 - 0s 1ms/step - loss: 8.0483 - acc: 0.5000\n",
      "Epoch 54/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.1909 - acc: 0.609 - 0s 1ms/step - loss: 7.0968 - acc: 0.5541\n",
      "Epoch 55/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.7548 - acc: 0.531 - 0s 1ms/step - loss: 6.9311 - acc: 0.5270\n",
      "Epoch 56/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.5450 - acc: 0.500 - 0s 1ms/step - loss: 7.6145 - acc: 0.5000\n",
      "Epoch 57/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.6205 - acc: 0.578 - 0s 1ms/step - loss: 6.5971 - acc: 0.5811\n",
      "Epoch 58/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.5450 - acc: 0.562 - 0s 2ms/step - loss: 6.7496 - acc: 0.5541\n",
      "Epoch 59/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.9874 - acc: 0.546 - 0s 1ms/step - loss: 7.1322 - acc: 0.5405\n",
      "Epoch 60/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.4808 - acc: 0.531 - 0s 1ms/step - loss: 7.3412 - acc: 0.5405\n",
      "Epoch 61/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.3062 - acc: 0.593 - 0s 1ms/step - loss: 6.5431 - acc: 0.5811\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 7.2818 - acc: 0.531 - 0s 1ms/step - loss: 6.7334 - acc: 0.5676\n",
      "Epoch 63/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.8014 - acc: 0.609 - 0s 1ms/step - loss: 5.7009 - acc: 0.6081\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.6877 - acc: 0.546 - 0s 2ms/step - loss: 6.4374 - acc: 0.5676\n",
      "Epoch 65/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.0685 - acc: 0.609 - 0s 2ms/step - loss: 6.1197 - acc: 0.6081\n",
      "Epoch 66/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.7881 - acc: 0.625 - 0s 2ms/step - loss: 5.5714 - acc: 0.6216\n",
      "Epoch 67/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.3287 - acc: 0.578 - 0s 2ms/step - loss: 6.5625 - acc: 0.5676\n",
      "Epoch 68/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.8231 - acc: 0.562 - 0s 2ms/step - loss: 6.7723 - acc: 0.5676\n",
      "Epoch 69/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.3097 - acc: 0.703 - 0s 2ms/step - loss: 5.0342 - acc: 0.6622\n",
      "Epoch 70/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.7745 - acc: 0.625 - 0s 2ms/step - loss: 5.5839 - acc: 0.6081\n",
      "Epoch 71/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.3114 - acc: 0.531 - 0s 1ms/step - loss: 7.1946 - acc: 0.5405\n",
      "Epoch 72/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.4937 - acc: 0.562 - 0s 1ms/step - loss: 6.6763 - acc: 0.5541\n",
      "Epoch 73/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.0667 - acc: 0.515 - 0s 1ms/step - loss: 7.0585 - acc: 0.5135\n",
      "Epoch 74/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.3841 - acc: 0.515 - 0s 1ms/step - loss: 6.8629 - acc: 0.5405\n",
      "Epoch 75/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.7189 - acc: 0.500 - 0s 1ms/step - loss: 7.1141 - acc: 0.5405\n",
      "Epoch 76/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.0012 - acc: 0.531 - 0s 1ms/step - loss: 6.4160 - acc: 0.5676\n",
      "Epoch 77/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.9805 - acc: 0.562 - 0s 1ms/step - loss: 6.6906 - acc: 0.5811\n",
      "Epoch 78/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.8889 - acc: 0.625 - 0s 1ms/step - loss: 6.3999 - acc: 0.5946\n",
      "Epoch 79/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.0247 - acc: 0.609 - 0s 1ms/step - loss: 6.2546 - acc: 0.5946\n",
      "Epoch 80/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.1911 - acc: 0.593 - 0s 1ms/step - loss: 5.7901 - acc: 0.6216\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.8203 - acc: 0.640 - 0s 1ms/step - loss: 5.9114 - acc: 0.5811\n",
      "Epoch 82/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.7189 - acc: 0.593 - 0s 1ms/step - loss: 5.6523 - acc: 0.5946\n",
      "Epoch 83/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6.6131 - acc: 0.562 - 0s 1ms/step - loss: 6.1551 - acc: 0.5946\n",
      "Epoch 84/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.3396 - acc: 0.640 - 0s 1ms/step - loss: 5.7071 - acc: 0.6216\n",
      "Epoch 85/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.6690 - acc: 0.593 - 0s 1ms/step - loss: 5.0092 - acc: 0.6216\n",
      "Epoch 86/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.2125 - acc: 0.656 - 0s 1ms/step - loss: 5.6709 - acc: 0.6216\n",
      "Epoch 87/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.8714 - acc: 0.562 - 0s 1ms/step - loss: 5.5136 - acc: 0.5946\n",
      "Epoch 88/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.3441 - acc: 0.718 - 0s 1ms/step - loss: 4.8972 - acc: 0.6757\n",
      "Epoch 89/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.2159 - acc: 0.734 - 0s 1ms/step - loss: 5.2720 - acc: 0.6622\n",
      "Epoch 90/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.8013 - acc: 0.609 - 0s 1ms/step - loss: 5.8886 - acc: 0.6081\n",
      "Epoch 91/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.9886 - acc: 0.625 - 0s 1ms/step - loss: 5.6174 - acc: 0.6486\n",
      "Epoch 92/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.4580 - acc: 0.640 - 0s 1ms/step - loss: 5.2126 - acc: 0.6486\n",
      "Epoch 93/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.2121 - acc: 0.671 - 0s 2ms/step - loss: 5.1612 - acc: 0.6757\n",
      "Epoch 94/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.7909 - acc: 0.625 - 0s 1ms/step - loss: 5.6618 - acc: 0.6351\n",
      "Epoch 95/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7.2610 - acc: 0.531 - 0s 1ms/step - loss: 6.3043 - acc: 0.5811\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.2434 - acc: 0.640 - 0s 1ms/step - loss: 5.4061 - acc: 0.6351\n",
      "Epoch 97/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.3788 - acc: 0.703 - 0s 1ms/step - loss: 4.8762 - acc: 0.6757\n",
      "Epoch 98/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.0517 - acc: 0.671 - 0s 1ms/step - loss: 5.0224 - acc: 0.6757\n",
      "Epoch 99/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 4.9970 - acc: 0.687 - 0s 1ms/step - loss: 5.1930 - acc: 0.6757\n",
      "Epoch 100/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 5.2132 - acc: 0.656 - 0s 2ms/step - loss: 4.9443 - acc: 0.6757\n",
      "50/50 [==============================] - ETA:  - 0s 4ms/step\n",
      "Test score: 7.11205125809\n",
      "Test accuracy: 0.540000009537\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(64, 4, activation='relu', input_shape=(220,1)))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "model.fit(X_train_1D, y_train_hot, epochs=100, batch_size=64)\n",
    "score, acc = model.evaluate(X_test_1D, y_test_hot, batch_size=32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 217, 64)           320       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 108, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 108, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               884864    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 893,700\n",
      "Trainable params: 893,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 74 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 4.4551 - acc: 0.4189 - val_loss: 3.8366 - val_acc: 0.2600\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.3179 - acc: 0.3649 - val_loss: 4.2456 - val_acc: 0.3800\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 6.2118 - acc: 0.2973 - val_loss: 2.7068 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 4.1150 - acc: 0.3514 - val_loss: 2.5751 - val_acc: 0.5200\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 3.2040 - acc: 0.3514 - val_loss: 2.0037 - val_acc: 0.2600\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.2131 - acc: 0.3649 - val_loss: 1.2034 - val_acc: 0.5200\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.7316 - acc: 0.5135 - val_loss: 1.0329 - val_acc: 0.5800\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.1240 - acc: 0.5811 - val_loss: 1.1737 - val_acc: 0.5800\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.1110 - acc: 0.5811 - val_loss: 0.8704 - val_acc: 0.6800\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.2150 - acc: 0.4865 - val_loss: 0.8143 - val_acc: 0.6600\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9623 - acc: 0.6351 - val_loss: 0.8385 - val_acc: 0.6200\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0714 - acc: 0.5811 - val_loss: 0.8152 - val_acc: 0.6400\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8058 - acc: 0.5811 - val_loss: 0.7826 - val_acc: 0.7000\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0239 - acc: 0.5541 - val_loss: 0.7977 - val_acc: 0.6600\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7836 - acc: 0.6892 - val_loss: 0.8087 - val_acc: 0.6200\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9084 - acc: 0.6351 - val_loss: 0.8180 - val_acc: 0.6800\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7697 - acc: 0.7703 - val_loss: 0.7685 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7643 - acc: 0.7027 - val_loss: 0.7911 - val_acc: 0.6200\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7039 - acc: 0.7027 - val_loss: 0.8141 - val_acc: 0.6200\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6613 - acc: 0.7297 - val_loss: 0.7177 - val_acc: 0.6800\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6962 - acc: 0.7297 - val_loss: 0.7671 - val_acc: 0.6800\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.5639 - acc: 0.7703 - val_loss: 0.7055 - val_acc: 0.7000\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6206 - acc: 0.7297 - val_loss: 0.7992 - val_acc: 0.6400\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7454 - acc: 0.6757 - val_loss: 0.7566 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6149 - acc: 0.7297 - val_loss: 0.7367 - val_acc: 0.6600\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6808 - acc: 0.6892 - val_loss: 0.7690 - val_acc: 0.6800\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6392 - acc: 0.7162 - val_loss: 0.7275 - val_acc: 0.6600\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.5330 - acc: 0.7568 - val_loss: 0.7839 - val_acc: 0.6800\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6169 - acc: 0.7703 - val_loss: 0.8085 - val_acc: 0.6000\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7778 - acc: 0.7027 - val_loss: 0.7725 - val_acc: 0.6400\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5642 - acc: 0.7973 - val_loss: 0.7530 - val_acc: 0.6800\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.5912 - acc: 0.7973 - val_loss: 0.7339 - val_acc: 0.6800\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5123 - acc: 0.7973 - val_loss: 0.8088 - val_acc: 0.6200\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5821 - acc: 0.7568 - val_loss: 0.7907 - val_acc: 0.7000\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6156 - acc: 0.7162 - val_loss: 0.8108 - val_acc: 0.6200\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6562 - acc: 0.7703 - val_loss: 0.8066 - val_acc: 0.7200\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6325 - acc: 0.7027 - val_loss: 0.7578 - val_acc: 0.6400\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.5016 - acc: 0.8378 - val_loss: 0.7826 - val_acc: 0.6400\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4601 - acc: 0.8243 - val_loss: 0.8387 - val_acc: 0.6400\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5398 - acc: 0.7973 - val_loss: 0.7969 - val_acc: 0.6800\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4588 - acc: 0.7703 - val_loss: 0.7686 - val_acc: 0.6600\n",
      "Epoch 42/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3750 - acc: 0.8243 - val_loss: 0.7802 - val_acc: 0.7200\n",
      "Epoch 43/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.4024 - acc: 0.8514 - val_loss: 0.7854 - val_acc: 0.6800\n",
      "Epoch 44/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4220 - acc: 0.7973 - val_loss: 0.8333 - val_acc: 0.7000\n",
      "Epoch 45/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2984 - acc: 0.8919 - val_loss: 0.8036 - val_acc: 0.6800\n",
      "Epoch 46/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3688 - acc: 0.8919 - val_loss: 0.8186 - val_acc: 0.7600\n",
      "Epoch 47/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.5556 - acc: 0.7973 - val_loss: 0.9051 - val_acc: 0.6000\n",
      "Epoch 48/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4997 - acc: 0.7162 - val_loss: 0.9783 - val_acc: 0.6400\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4418 - acc: 0.8108 - val_loss: 0.9028 - val_acc: 0.6600\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4113 - acc: 0.8108 - val_loss: 0.7136 - val_acc: 0.7200\n",
      "Epoch 51/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3937 - acc: 0.8108 - val_loss: 0.8414 - val_acc: 0.7000\n",
      "Epoch 52/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4195 - acc: 0.7838 - val_loss: 0.7118 - val_acc: 0.6600\n",
      "Epoch 53/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4446 - acc: 0.8649 - val_loss: 1.0181 - val_acc: 0.6000\n",
      "Epoch 54/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3557 - acc: 0.8514 - val_loss: 0.9849 - val_acc: 0.5800\n",
      "Epoch 55/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.3423 - acc: 0.8108 - val_loss: 0.7347 - val_acc: 0.7000\n",
      "Epoch 56/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3827 - acc: 0.8514 - val_loss: 0.9252 - val_acc: 0.7200\n",
      "Epoch 57/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5018 - acc: 0.7973 - val_loss: 0.6829 - val_acc: 0.7000\n",
      "Epoch 58/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.3730 - acc: 0.9054 - val_loss: 0.7679 - val_acc: 0.6800\n",
      "Epoch 59/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2391 - acc: 0.9189 - val_loss: 0.7039 - val_acc: 0.7400\n",
      "Epoch 60/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3297 - acc: 0.8378 - val_loss: 0.8060 - val_acc: 0.7200\n",
      "Epoch 61/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3226 - acc: 0.8243 - val_loss: 0.8450 - val_acc: 0.6800\n",
      "Epoch 62/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2612 - acc: 0.8514 - val_loss: 0.8954 - val_acc: 0.7200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2437 - acc: 0.9054 - val_loss: 0.7865 - val_acc: 0.7000\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2855 - acc: 0.8919 - val_loss: 0.6931 - val_acc: 0.7200\n",
      "Epoch 65/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2401 - acc: 0.9459 - val_loss: 0.7940 - val_acc: 0.7200\n",
      "Epoch 66/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2577 - acc: 0.9189 - val_loss: 0.9277 - val_acc: 0.7000\n",
      "Epoch 67/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2361 - acc: 0.9324 - val_loss: 0.9133 - val_acc: 0.6600\n",
      "Epoch 68/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2140 - acc: 0.9054 - val_loss: 0.7686 - val_acc: 0.7200\n",
      "Epoch 69/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1728 - acc: 0.9730 - val_loss: 0.8273 - val_acc: 0.6800\n",
      "Epoch 70/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2121 - acc: 0.9054 - val_loss: 0.7090 - val_acc: 0.7400\n",
      "Epoch 71/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2557 - acc: 0.9054 - val_loss: 1.1258 - val_acc: 0.6200\n",
      "Epoch 72/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1821 - acc: 0.9324 - val_loss: 0.8419 - val_acc: 0.7200\n",
      "Epoch 73/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1929 - acc: 0.9054 - val_loss: 0.7555 - val_acc: 0.7200\n",
      "Epoch 74/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2179 - acc: 0.8919 - val_loss: 0.9204 - val_acc: 0.6600\n",
      "Epoch 75/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1794 - acc: 0.9730 - val_loss: 0.7427 - val_acc: 0.7200\n",
      "Epoch 76/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1587 - acc: 0.9459 - val_loss: 0.9416 - val_acc: 0.7200\n",
      "Epoch 77/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1463 - acc: 0.9459 - val_loss: 0.9355 - val_acc: 0.6800\n",
      "Epoch 78/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1233 - acc: 0.9595 - val_loss: 0.8437 - val_acc: 0.7200\n",
      "Epoch 79/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1013 - acc: 0.9865 - val_loss: 0.8329 - val_acc: 0.7600\n",
      "Epoch 80/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1759 - acc: 0.9324 - val_loss: 1.0269 - val_acc: 0.6800\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1319 - acc: 0.9595 - val_loss: 1.1106 - val_acc: 0.7000\n",
      "Epoch 82/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1264 - acc: 0.9459 - val_loss: 1.0170 - val_acc: 0.6600\n",
      "Epoch 83/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1298 - acc: 0.9730 - val_loss: 0.8724 - val_acc: 0.7400\n",
      "Epoch 84/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1104 - acc: 0.9865 - val_loss: 1.0167 - val_acc: 0.7200\n",
      "Epoch 85/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1233 - acc: 0.9459 - val_loss: 0.8362 - val_acc: 0.7600\n",
      "Epoch 86/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1156 - acc: 0.9595 - val_loss: 1.2457 - val_acc: 0.7000\n",
      "Epoch 87/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1593 - acc: 0.9595 - val_loss: 0.9307 - val_acc: 0.7600\n",
      "Epoch 88/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0930 - acc: 0.9595 - val_loss: 0.9628 - val_acc: 0.7000\n",
      "Epoch 89/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1218 - acc: 0.9730 - val_loss: 0.9095 - val_acc: 0.7000\n",
      "Epoch 90/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1219 - acc: 0.9595 - val_loss: 1.0324 - val_acc: 0.7400\n",
      "Epoch 91/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1138 - acc: 0.9865 - val_loss: 1.1198 - val_acc: 0.7600\n",
      "Epoch 92/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1167 - acc: 0.9730 - val_loss: 0.8111 - val_acc: 0.7800\n",
      "Epoch 93/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1210 - acc: 0.9730 - val_loss: 1.3755 - val_acc: 0.6800\n",
      "Epoch 94/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2789 - acc: 0.8649 - val_loss: 0.8205 - val_acc: 0.6800\n",
      "Epoch 95/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2497 - acc: 0.9189 - val_loss: 1.0108 - val_acc: 0.6600\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1591 - acc: 0.9324 - val_loss: 0.8705 - val_acc: 0.8000\n",
      "Epoch 97/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0785 - acc: 1.0000 - val_loss: 0.8281 - val_acc: 0.7600\n",
      "Epoch 98/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0550 - acc: 1.0000 - val_loss: 0.9210 - val_acc: 0.7400\n",
      "Epoch 99/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0764 - acc: 0.9865 - val_loss: 0.9274 - val_acc: 0.7000\n",
      "Epoch 100/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1170 - acc: 0.9459 - val_loss: 0.9903 - val_acc: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d4905d1eb8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA:  - 0s 420us/step\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test_hot, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99032165765762326"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72000000476837156"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 3, 2, 1, 2, 2, 0, 0, 2, 1, 3, 0, 2, 0, 2, 0, 3, 0, 2, 0,\n",
       "       0, 1, 1, 0, 0, 1, 3, 2, 2, 3, 0, 3, 0, 1, 2, 2, 0, 3, 3, 0, 0, 2, 0,\n",
       "       2, 0, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  1,  1,  0],\n",
       "       [ 1,  4,  1,  2],\n",
       "       [ 0,  1, 10,  2],\n",
       "       [ 0,  0,  5,  5]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'artifact': 100%|████| 40/40 [00:19<00:00,  2.00it/s]\n",
      "Saving vectors of label - 'extrahls': 100%|████| 19/19 [00:07<00:00,  2.43it/s]\n",
      "Saving vectors of label - 'murmur': 100%|██████| 34/34 [00:15<00:00,  2.13it/s]\n",
      "Saving vectors of label - 'normal': 100%|██████| 31/31 [00:14<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "#chroma features\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array_chroma(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 100\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 4\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_train_hot = to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data_to_array_chroma(path=DATA_PATH, max_len=11):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        # Init chroma vectors\n",
    "        chroma_vectors = []\n",
    "\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label) if '.DS_Store' not in wavfile ]\n",
    "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
    "            chroma = wav2chroma(wavfile, max_len=max_len)\n",
    "            chroma_vectors.append(chroma)\n",
    "        np.save(label + '.npy', chroma_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 19, 10, 32)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 18, 9, 48)         6192      \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 17, 8, 120)        23160     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 4, 120)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8, 4, 120)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               491648    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 529,676\n",
      "Trainable params: 529,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 20, 11)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 20, 11)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_chroma = X_train.reshape(74,20,11,1)\n",
    "X_test_chroma = X_test.reshape(50,20,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 74 samples, validate on 50 samples\n",
      "Epoch 1/100\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 4.6687 - acc: 0.2297 - val_loss: 1.8286 - val_acc: 0.6000\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 4.1789 - acc: 0.3108 - val_loss: 1.2348 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.8126 - acc: 0.3649 - val_loss: 1.4487 - val_acc: 0.5600\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.9082 - acc: 0.4730 - val_loss: 1.7994 - val_acc: 0.4200\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.6630 - acc: 0.4730 - val_loss: 1.2796 - val_acc: 0.6200\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.1142 - acc: 0.4054 - val_loss: 0.8822 - val_acc: 0.7000\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.4825 - acc: 0.5405 - val_loss: 1.5774 - val_acc: 0.3400\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.2946 - acc: 0.4865 - val_loss: 0.9497 - val_acc: 0.5800\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0445 - acc: 0.5676 - val_loss: 0.7781 - val_acc: 0.6800\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8669 - acc: 0.6081 - val_loss: 0.7657 - val_acc: 0.6200\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8668 - acc: 0.6486 - val_loss: 0.9068 - val_acc: 0.6200\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8055 - acc: 0.6892 - val_loss: 0.9169 - val_acc: 0.6200\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8762 - acc: 0.6486 - val_loss: 0.7869 - val_acc: 0.6400\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7760 - acc: 0.6486 - val_loss: 0.7822 - val_acc: 0.7000\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7572 - acc: 0.6216 - val_loss: 0.9867 - val_acc: 0.6400\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8086 - acc: 0.6622 - val_loss: 0.7687 - val_acc: 0.7200\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7498 - acc: 0.6892 - val_loss: 0.8493 - val_acc: 0.6600\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8623 - acc: 0.6486 - val_loss: 0.8099 - val_acc: 0.6800\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9180 - acc: 0.6081 - val_loss: 0.9795 - val_acc: 0.5400\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7467 - acc: 0.6757 - val_loss: 0.7521 - val_acc: 0.6800\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.6812 - acc: 0.7973 - val_loss: 0.8191 - val_acc: 0.6400\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6350 - acc: 0.7297 - val_loss: 0.7477 - val_acc: 0.6400\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5775 - acc: 0.7568 - val_loss: 0.7031 - val_acc: 0.7200\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.6146 - acc: 0.7432 - val_loss: 0.7886 - val_acc: 0.7000\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.5631 - acc: 0.8108 - val_loss: 0.7664 - val_acc: 0.6600\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4063 - acc: 0.8784 - val_loss: 0.7753 - val_acc: 0.7600\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5508 - acc: 0.7568 - val_loss: 0.7683 - val_acc: 0.7200\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5206 - acc: 0.7568 - val_loss: 0.8909 - val_acc: 0.6600\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4712 - acc: 0.8243 - val_loss: 0.8084 - val_acc: 0.6800\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.7183 - acc: 0.7162 - val_loss: 0.7757 - val_acc: 0.6800\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4778 - acc: 0.8514 - val_loss: 0.6906 - val_acc: 0.7600\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5345 - acc: 0.7703 - val_loss: 0.8740 - val_acc: 0.6000\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4633 - acc: 0.8378 - val_loss: 0.7125 - val_acc: 0.6800\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5394 - acc: 0.7568 - val_loss: 1.1134 - val_acc: 0.5800\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5695 - acc: 0.7838 - val_loss: 0.6823 - val_acc: 0.6600\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.4085 - acc: 0.8378 - val_loss: 0.7470 - val_acc: 0.6600\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4712 - acc: 0.8243 - val_loss: 0.7415 - val_acc: 0.6600\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.4634 - acc: 0.7973 - val_loss: 0.7307 - val_acc: 0.7200\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4134 - acc: 0.8784 - val_loss: 0.7893 - val_acc: 0.6600\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.4069 - acc: 0.8784 - val_loss: 0.7317 - val_acc: 0.7600\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4755 - acc: 0.7838 - val_loss: 0.7574 - val_acc: 0.6800\n",
      "Epoch 42/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4474 - acc: 0.8378 - val_loss: 0.7113 - val_acc: 0.7400\n",
      "Epoch 43/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.5469 - acc: 0.7568 - val_loss: 0.7362 - val_acc: 0.6800\n",
      "Epoch 44/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4133 - acc: 0.8243 - val_loss: 0.7409 - val_acc: 0.6800\n",
      "Epoch 45/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3708 - acc: 0.8514 - val_loss: 0.9621 - val_acc: 0.6800\n",
      "Epoch 46/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3610 - acc: 0.8649 - val_loss: 0.8232 - val_acc: 0.7000\n",
      "Epoch 47/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.3954 - acc: 0.8649 - val_loss: 0.7517 - val_acc: 0.7200\n",
      "Epoch 48/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2873 - acc: 0.8919 - val_loss: 0.8379 - val_acc: 0.6600\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4242 - acc: 0.7973 - val_loss: 0.7124 - val_acc: 0.7200\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2822 - acc: 0.8784 - val_loss: 0.9771 - val_acc: 0.6200\n",
      "Epoch 51/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.2666 - acc: 0.9189 - val_loss: 0.8671 - val_acc: 0.6400\n",
      "Epoch 52/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.3374 - acc: 0.8378 - val_loss: 1.0496 - val_acc: 0.6800\n",
      "Epoch 53/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.3666 - acc: 0.8378 - val_loss: 1.0223 - val_acc: 0.6200\n",
      "Epoch 54/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.4121 - acc: 0.8243 - val_loss: 1.1052 - val_acc: 0.6400\n",
      "Epoch 55/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.3889 - acc: 0.8108 - val_loss: 1.0805 - val_acc: 0.6600\n",
      "Epoch 56/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.3765 - acc: 0.8243 - val_loss: 0.9419 - val_acc: 0.6000\n",
      "Epoch 57/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2609 - acc: 0.9189 - val_loss: 0.8962 - val_acc: 0.6200\n",
      "Epoch 58/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2836 - acc: 0.8919 - val_loss: 0.8851 - val_acc: 0.6200\n",
      "Epoch 59/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2778 - acc: 0.9189 - val_loss: 0.8051 - val_acc: 0.7200\n",
      "Epoch 60/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1512 - acc: 0.9595 - val_loss: 0.9029 - val_acc: 0.6600\n",
      "Epoch 61/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1937 - acc: 0.9595 - val_loss: 0.8280 - val_acc: 0.6800\n",
      "Epoch 62/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1897 - acc: 0.9054 - val_loss: 1.0191 - val_acc: 0.6000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2003 - acc: 0.9324 - val_loss: 0.8298 - val_acc: 0.6400\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1758 - acc: 0.9459 - val_loss: 0.8853 - val_acc: 0.6600\n",
      "Epoch 65/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2848 - acc: 0.8784 - val_loss: 0.8823 - val_acc: 0.7000\n",
      "Epoch 66/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1484 - acc: 0.9730 - val_loss: 1.1031 - val_acc: 0.6200\n",
      "Epoch 67/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1824 - acc: 0.9324 - val_loss: 1.1233 - val_acc: 0.6400\n",
      "Epoch 68/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1667 - acc: 0.9324 - val_loss: 1.0058 - val_acc: 0.7200\n",
      "Epoch 69/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.2314 - acc: 0.8784 - val_loss: 1.0962 - val_acc: 0.6400\n",
      "Epoch 70/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1803 - acc: 0.9054 - val_loss: 0.8764 - val_acc: 0.7200\n",
      "Epoch 71/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1387 - acc: 0.9459 - val_loss: 0.9620 - val_acc: 0.6800\n",
      "Epoch 72/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1437 - acc: 0.9595 - val_loss: 1.0118 - val_acc: 0.6600\n",
      "Epoch 73/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1118 - acc: 0.9865 - val_loss: 1.0022 - val_acc: 0.6400\n",
      "Epoch 74/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1471 - acc: 0.9730 - val_loss: 1.3068 - val_acc: 0.6200\n",
      "Epoch 75/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1172 - acc: 0.9730 - val_loss: 1.2908 - val_acc: 0.6400\n",
      "Epoch 76/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0969 - acc: 0.9730 - val_loss: 1.1946 - val_acc: 0.6400\n",
      "Epoch 77/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0875 - acc: 0.9865 - val_loss: 1.4198 - val_acc: 0.6200\n",
      "Epoch 78/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1207 - acc: 0.9459 - val_loss: 1.2353 - val_acc: 0.6400\n",
      "Epoch 79/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0848 - acc: 0.9865 - val_loss: 1.2939 - val_acc: 0.6400\n",
      "Epoch 80/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1474 - acc: 0.9595 - val_loss: 1.2108 - val_acc: 0.6400\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1290 - acc: 0.9865 - val_loss: 1.3053 - val_acc: 0.6000\n",
      "Epoch 82/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1191 - acc: 0.9730 - val_loss: 1.2832 - val_acc: 0.6200\n",
      "Epoch 83/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1587 - acc: 0.9459 - val_loss: 0.9712 - val_acc: 0.6600\n",
      "Epoch 84/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1309 - acc: 0.9324 - val_loss: 1.1771 - val_acc: 0.6200\n",
      "Epoch 85/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0344 - acc: 1.0000 - val_loss: 1.2089 - val_acc: 0.6200\n",
      "Epoch 86/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0978 - acc: 0.9730 - val_loss: 0.9955 - val_acc: 0.6800\n",
      "Epoch 87/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0749 - acc: 0.9730 - val_loss: 1.4503 - val_acc: 0.6200\n",
      "Epoch 88/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.1052 - acc: 0.9595 - val_loss: 1.2765 - val_acc: 0.6400\n",
      "Epoch 89/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0976 - acc: 0.9865 - val_loss: 1.4170 - val_acc: 0.5800\n",
      "Epoch 90/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0600 - acc: 0.9730 - val_loss: 1.1193 - val_acc: 0.6400\n",
      "Epoch 91/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0778 - acc: 0.9730 - val_loss: 1.1868 - val_acc: 0.6400\n",
      "Epoch 92/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0390 - acc: 1.0000 - val_loss: 1.1974 - val_acc: 0.6200\n",
      "Epoch 93/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0768 - acc: 0.9865 - val_loss: 1.2800 - val_acc: 0.6000\n",
      "Epoch 94/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1691 - acc: 0.9595 - val_loss: 1.0387 - val_acc: 0.7400\n",
      "Epoch 95/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1032 - acc: 0.9865 - val_loss: 1.6212 - val_acc: 0.6200\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0596 - acc: 0.9865 - val_loss: 1.4254 - val_acc: 0.6000\n",
      "Epoch 97/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1079 - acc: 0.9730 - val_loss: 1.0665 - val_acc: 0.6800\n",
      "Epoch 98/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.1071 - acc: 0.9595 - val_loss: 1.2244 - val_acc: 0.6200\n",
      "Epoch 99/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.0569 - acc: 1.0000 - val_loss: 1.2160 - val_acc: 0.6600\n",
      "Epoch 100/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.0378 - acc: 1.0000 - val_loss: 1.2159 - val_acc: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d492b62f98>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train_chroma, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test_chroma, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - ETA:  - 0s 630us/step\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test_chroma, y_test_hot, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.215890703201294"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65999999523162844"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
